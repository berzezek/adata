import json
import aiohttp
import asyncio
import os
from dotenv import load_dotenv
import urllib3
import time

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

load_dotenv()

proxie_urls = {
    "http": os.getenv("HTTP_PROXY"),
    "https": os.getenv("HTTPS_PROXY"),
}

base_url = "https://api.adata.kz/api/company/info/check/"
API_TOKEN = os.getenv("API_TOKEN")
batch_size = int(os.getenv("BATCH_SIZE"))*10
ERROR_LOG_FILE = "response_tokens/error_log_token_responses.json"

import requests
import time

def send_get_request(token, bin, endpoint, proxies, retries=3, delay=30):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç GET-–∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∑–∞–ø–∏—Å–∏"""
    url = f"{base_url}{API_TOKEN}?token={token}"
    for attempt in range(retries):
        try:
            response = requests.get(url, proxies=proxies, verify=False, timeout=30)
            if response.status_code == 200:
                response_json = response.json()
                message = response_json.get("message", "")

                if message == "wait":
                    return {"bin": bin, "endpoint": endpoint, "token": token, "status": "wait"}
                elif message == "ready":
                    data = response_json.get("data", {})
                    return {"bin": bin, "endpoint": endpoint, "data": data, "status": "ready"}
            elif response.status_code == 404:
                return {"bin": bin, "endpoint": endpoint, "token": token, "status": "not_found"}
            else:
                log_error({"bin": bin, "endpoint": endpoint, "status": response.status_code, "error": "Server error or timeout"})
                print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}: –°–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª {response.status_code} (BIN {bin})")
        except requests.exceptions.Timeout:
            log_error({"bin": bin, "endpoint": endpoint, "error": "Timeout error"})
            print(f"‚è≥ –¢–∞–π–º-–∞—É—Ç –¥–ª—è BIN {bin}. –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}...")
        except requests.exceptions.RequestException as e:
            log_error({"bin": bin, "endpoint": endpoint, "error": f"Client error: {e}"})
            print(f"‚ö†Ô∏è –ö–ª–∏–µ–Ω—Ç—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}. –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}...")

        if attempt < retries - 1:  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
            print(f"üîÑ –û–∂–∏–¥–∞–Ω–∏–µ {delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
            time.sleep(delay)

    return {"bin": bin, "endpoint": endpoint, "status": "Failed after retries"}


def process_batches(start_index, end_index, proxies):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ batch_size"""
    responses = load_responses(f"response_tokens/response_tokens_{start_index}_{end_index}.json")
    if not isinstance(responses, list):
        print("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ response_tokens.json")
        return

    wait_data = []
    ready_data = []
    not_found_data = []
    error = []

    try:
        for i in range(0, len(responses), batch_size):
            try:
                start_time = time.monotonic()

                batch = responses[i:i + batch_size]  # –ë–µ—Ä–µ–º –ø–æ batch_size –∑–∞–ø–∏—Å–µ–π

                for response in batch:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–æ–∫–µ–Ω, BIN –∏ endpoint —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                    if response.get("token") and response.get("bin") and response.get("endpoint"):
                        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ BIN
                        result = send_get_request(response["token"], response["bin"], response["endpoint"], proxies)
                        if result:
                            if result["status"] == "wait":
                                wait_data.append(result)
                            elif result["status"] == "ready":
                                ready_data.append(result)
                            elif result["status"] == "not_found":
                                not_found_data.append(result)
                            else:
                                error.append(result)

                        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É –≤ 1 —Å–µ–∫—É–Ω–¥—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        # time.sleep(1)
                print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ {min(i + batch_size, len(responses))}/{len(responses)} –∑–∞–ø–∏—Å–µ–π.")

                elapsed_time = time.monotonic() - start_time  # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±–∞—Ç—á–∞

                # –ñ–¥—ë–º, –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–Ω—è–ª–æ –º–µ–Ω—å—à–µ 1 –º–∏–Ω—É—Ç—ã
                if elapsed_time < 60:
                    remaining_time = 60 - elapsed_time
                    print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {remaining_time:.2f} —Å–µ–∫—É–Ω–¥ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –±–∞—Ç—á–∞...")
                    time.sleep(remaining_time)
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

    except Exception as e:
        print(f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
    finally:
        save_responses_to_file(f"results/wait_{start_index}_{end_index}.json", wait_data)
        save_responses_to_file(f"results/responses_{start_index}_{end_index}.json", ready_data)
        save_responses_to_file(f"results/fl_{start_index}_{end_index}.json", not_found_data)
        save_responses_to_file(f"results/error_{start_index}_{end_index}.json", error)
        print("\n‚úÖ –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")


def save_responses_to_file(filename, data_list):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö –≤ JSON-—Ñ–∞–π–ª"""
    try:
        with open(filename, "r", encoding="utf-8") as file:
            existing_data = json.load(file)
    except (FileNotFoundError, json.JSONDecodeError):
        existing_data = []

    existing_data.extend(data_list)

    with open(filename, "w", encoding="utf-8") as file:
        json.dump(existing_data, file, ensure_ascii=False, indent=4)

def log_error(error_data):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫–∏ –≤ –ª–æ–≥-—Ñ–∞–π–ª"""
    try:
        with open(ERROR_LOG_FILE, "r", encoding="utf-8") as file:
            existing_errors = json.load(file)
    except (FileNotFoundError, json.JSONDecodeError):
        existing_errors = []

    existing_errors.append(error_data)

    with open(ERROR_LOG_FILE, "w", encoding="utf-8") as file:
        json.dump(existing_errors, file, ensure_ascii=False, indent=4)

def load_responses(filename="response_tokens/response_tokens.json"):
    """–ß–∏—Ç–∞–µ—Ç JSON-—Ñ–∞–π–ª –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
    try:
        with open(filename, "r", encoding="utf-8") as file:
            response_data = json.load(file)
        return response_data
    except FileNotFoundError:
        return {"error": f"–§–∞–π–ª '{filename}' –Ω–µ –Ω–∞–π–¥–µ–Ω"}
    except json.JSONDecodeError:
        return {"error": "–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON"}

def get_data(start_index, end_index, proxies):
    process_batches(start_index, end_index, proxies)

if __name__ == "__main__":
    start_index = int(input("–í–≤–µ–¥–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å BIN: "))
    end_index = int(input("–í–≤–µ–¥–∏—Ç–µ –∫–æ–Ω–µ—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å BIN: "))
    get_data(start_index, end_index, proxie_urls)
